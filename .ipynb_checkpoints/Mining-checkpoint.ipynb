{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit-Mining\n",
    "## Die Ziele im Projekt\n",
    "\n",
    "Allgemein ist die Aufgabe Texte systematisch aus dem Web zu gewinnen und diese dann auszuwerten.\n",
    "\n",
    "Wir haben uns zur Aufgabe gemacht durch diverse Reddit-Spiele-Foren (https://reddit.com) zu crawlen und verschiedene Aussagen über die Nutzer und die Spiele der einzelnen Foren zu machen:\n",
    "    - Wie freundlich sind die Spieler der einzelnen Foren?\n",
    "    - In welchen Spielen wird am meisten im Web diskutiert?\n",
    "    \n",
    "Zusätzlich ist es das Ziel, einen beliebigen Text zu einem der Spiele zuzuordnen.\n",
    "\n",
    "Zur Datenspeicherung wird nach Aufgabe eine SQL-Lite Datenbank verwendet.   \n",
    "\n",
    "Wichtig für uns ist die modularität, sodass wir schnell weitere Reddit-Foren hinzufügen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Dieser Abschnitt behandelt das gesamte Scraping der einzelnen Reddit Pages.\n",
    "\n",
    "Zunächst werden die Spieleforen, die benutzt werden, angegegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "games= {}\n",
    "games[\"dota2\"] = 'https://www.reddit.com/r/DotA2/'\n",
    "games[\"csgo\"] = 'https://www.reddit.com/r/GlobalOffensive/'\n",
    "#games[\"spacex\"] = 'https://www.reddit.com/r/spacex/' #<- War lediglich aus interesse\n",
    "#games[\"lol\"] = 'https://www.reddit.com/r/leagueoflegends/'\n",
    "#games[\"darksouls3\"] = 'https://www.reddit.com/r/darksouls3/'\n",
    "#games[\"witcher3\"] = 'https://www.reddit.com/r/Witcher3/'\n",
    "#games[\"smite\"] = 'https://www.reddit.com/r/Smite/'\n",
    "#games[\"aoe4\"] = 'https://www.reddit.com/r/aoe4/'\n",
    "#games[\"unrealtournament\"] = 'https://www.reddit.com/r/unrealtournament/'\n",
    "#games[\"battlefield1\"] = 'https://www.reddit.com/r/battlefield_one/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes werden Parameter, welche beispielsweise die Datenmenge bestimmen, initialisiert und definiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_per_forum = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann man eigentlich mit dem \"scrapen\" beginnen. Hierfür wird \"scrapy\" verwendet, der code orientiert sich an den Aufgabenblättern der Vorlesung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "#copy of sheet 05\n",
    "def gen_scrapy_response(url):\n",
    "    # define user agent to simulate interactive user\n",
    "    user_agent = 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "    req = requests.get(url, headers={ \"user-agent\": user_agent })\n",
    "    return scrapy.http.TextResponse(req.url, body=req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Analyse ist uns aufgefallen, dass alle Reddit-Foren zwar unterschiedliche Designs haben, aber immer die selbe Struktur (auch in Bezug auf den HTML-Baum und die CSS-Klassen) besitzen. Aus diesem Grund können wir das selbe vorgehen auf alle Foren anwenden.\n",
    "\n",
    "Zunächst werden alle (oder so viele wie möglich) Seiten aus den einzelnen Foren ausgelesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_pages = {}\n",
    "#extracts all reddit overview pages for each game analyzed\n",
    "for game in games:\n",
    "    link = games[game]\n",
    "    #predefine an empty list\n",
    "    reddit_pages[game] = []\n",
    "    for i in range(pages_per_forum-1):\n",
    "        x = gen_scrapy_response(link)\n",
    "        reddit_pages[game].append(x)\n",
    "        link = str(x.css(\"span.next-button > a::attr(href)\").extract_first()) #next button, missing if no other page exists\n",
    "        if(link == \"None\"): ##cancel if no other page exists\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden alle Threads auf den gegeben Seiten erfasst, in diesen steht der großteil der Daten (wie die einzelnen Texte). Diese werden in Listen gespeichert, welche wieder in einem Dictionary, sortiert nach den Foren, verwaltet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_threads = {}\n",
    "#extracts all redit threads from the pages available\n",
    "for game in reddit_pages:\n",
    "    #predefine an empty list\n",
    "    reddit_threads[game] = []\n",
    "    #iterate through all available pages per game\n",
    "    for page in reddit_pages[game]:\n",
    "        thread_links = page.css(\"a.comments::attr(href)\").extract() #comment button\n",
    "        reddit_threads[game].extend(thread_links)\n",
    "#cleaning old variables\n",
    "#del reddit_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem alle Links erfasst wurden, kann man durch diese Listen iterieren um die Daten zu erfassen. Die Daten werden in einer Liste aus Dictionaries gespeichert, diese dcits besitzen zunächst folgende Informationen:\n",
    "- game: Das Spiel für welches dieser Kommentar geschrieben wurde\n",
    "- thread: Der Titel des Threads, für welchen diese Kommentar geschrieben wurde\n",
    "- user: Der Benutzer der diesen Kommentar geschrieben hat\n",
    "- content: Der Text-Inhalt des Kommentars\n",
    "\n",
    "Um gleich die Daten etwas aufzubereiten werden Regular Expressions verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "all_comments = []\n",
    "#iterating through the games\n",
    "for game in reddit_threads:\n",
    "    #creating the new dictionary\n",
    "    comment = {}\n",
    "    #iterating through the threads of a game\n",
    "    for thread in reddit_threads[game]:\n",
    "        response = gen_scrapy_response(thread)\n",
    "        title = response.css(\"a.title::text\").extract_first()\n",
    "        comments = response.css(\"div.comment\")\n",
    "        for comment in comments:\n",
    "            user = comment.css(\"div.entry > p.tagline > a.author::text\").extract_first()\n",
    "            text = \" \".join(comment.css(\"div.usertext-body > div.md > *::text\").extract())\n",
    "            text = re.sub('\\s+',' ',text)\n",
    "            all_comments.append({\"game\":game,\"thread\":title,\"user\":user,\"content\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenbank\n",
    "\n",
    "Für die weitere Analyse werden die Daten in einer relationalen SQL-Lite Datenbank gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "def bar_plot(list_of_tuples, columns=('Wort', 'Anzahl'), title=None): \n",
    "\n",
    "    labels = [t[0] for t in list_of_tuples]\n",
    "    values = [t[1] for t in list_of_tuples]\n",
    "    dummy_pos = np.arange(len(labels))\n",
    "    \n",
    "    # Erstellung des Balkendiagramms\n",
    "    fig=plt.figure(figsize=(18, 10))\n",
    "    plt.bar(dummy_pos, values)\n",
    "    plt.xticks(dummy_pos, labels,  rotation=\"vertical\", fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(columns[0], fontsize=20)\n",
    "    plt.ylabel(columns[1], fontsize=20)\n",
    "    if title: \n",
    "        plt.title(title, fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
